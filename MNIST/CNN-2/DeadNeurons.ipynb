{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mj8Vf9hIs9I6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znaoCWQ6s-C5"
      },
      "outputs": [],
      "source": [
        "cd drive/MyDrive/Research1_code/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd mnist/CNN-2"
      ],
      "metadata": {
        "id": "syuHgaJJFuBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7GjZ6db0s6sS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys, os, random\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle, gzip\n",
        "from tqdm import tqdm,tqdm_notebook\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nsdPOAoGs516"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "seed_num = 81\n",
        "\n",
        "# For reproducibility when you run the file with .py\n",
        "torch.cuda.is_available()\n",
        "torch.manual_seed(seed_num)\n",
        "torch.cuda.manual_seed(seed_num)\n",
        "np.random.seed(seed_num)\n",
        "random.seed(seed_num)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "torch.backends.cudnn.deterministic =True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KRVeJN-Ys517"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation \n",
        "train_transform = transforms.Compose([transforms.RandomRotation(30), transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize([0.1307,],[0.3081,])])\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.1307,],[0.3081,])])\n",
        "\n",
        "# Splitting the training and test datasets\n",
        "train_data = datasets.MNIST(os.getcwd(), train=True,\n",
        "                              download=True, transform=train_transform)\n",
        "test_data = datasets.MNIST(os.getcwd(), train=False,\n",
        "                             download=True, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OU064Mmps517"
      },
      "outputs": [],
      "source": [
        "# Split the training set indices into training and validation set indices using 80:20 ratio\n",
        "np.random.seed(seed_num)\n",
        "len_trainset = len(train_data)\n",
        "index_list = list(range(len_trainset))\n",
        "np.random.shuffle(index_list)\n",
        "split_index = 50000\n",
        "train_indices, valid_indices =  index_list[:split_index], index_list[split_index:]\n",
        "\n",
        "# Creating Samplers for training and validation set using the indices\n",
        "np.random.seed(seed_num)\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "\n",
        "torch.manual_seed(seed_num)\n",
        "\n",
        "train_iterator = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
        "val_iterator = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
        "test_iterator = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xIEh83xn8XKP"
      },
      "outputs": [],
      "source": [
        "# CNN Model\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        \n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=0, bias= True)\n",
        "     \n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0, bias= True)\n",
        "        \n",
        "        # Fully connected 1\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 10,bias= True) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Set 1\n",
        "        out = F.max_pool2d(F.relu(self.cnn1(x)),2)\n",
        "        \n",
        "        # Set 2\n",
        "        out = F.max_pool2d(F.relu(self.cnn2(out)),2) \n",
        "        \n",
        "        # Flatten\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        # Dense\n",
        "        out = self.fc1(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "N6KFhL7U8XKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c577ac-cd26-4aca-fd94-a09527087fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model:\n",
            " CNNModel(\n",
            "  (cnn1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (cnn2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=800, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(seed_num)\n",
        "unit=128\n",
        "\n",
        "# Summary\n",
        "model = CNNModel()\n",
        "print(\"Model:\\n\",model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer names\n",
        "layer_name = [n for n, p in model.named_parameters()]\n",
        "layer_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_SXinXBgxYY",
        "outputId": "ab64a147-4ce3-41e9-b2ed-612844016a9f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cnn1.weight',\n",
              " 'cnn1.bias',\n",
              " 'cnn2.weight',\n",
              " 'cnn2.bias',\n",
              " 'fc1.weight',\n",
              " 'fc1.bias']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nyCQD4zl8XKT",
        "outputId": "919b198c-ce14-46d9-f1c1-a44d37357918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights done !\n",
            "cnn1.weight tensor(104, device='cuda:0')\n",
            "cnn1.bias tensor(13, device='cuda:0')\n",
            "cnn2.weight tensor(436, device='cuda:0')\n",
            "cnn2.bias tensor(28, device='cuda:0')\n",
            "fc1.weight tensor(780, device='cuda:0')\n",
            "fc1.bias tensor(9, device='cuda:0')\n",
            "Total Parameters: tensor(1370, device='cuda:0') \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Loading the weights of ternary model \n",
        "model = torch.load('CNN_2_quant.pt')\n",
        "model = model.cuda()\n",
        "print(\"Loading weights done !\")\n",
        "\n",
        "# Total number of ternary weights (+w, -w)\n",
        "totalParams = 0\n",
        "for i in layer_name:\n",
        "  print(i,(model.state_dict()[i] !=0).sum())\n",
        "  totalParams +=  (model.state_dict()[i] !=0).sum()\n",
        "    \n",
        "print(\"Total Parameters:\",totalParams, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pdjq7VQj8XKV",
        "outputId": "25c42cd2-40ed-440a-c89b-d94f2d16796c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number Of Images Tested = 10000\n",
            "\n",
            "Model Test Accuracy = 0.893\n"
          ]
        }
      ],
      "source": [
        "# Model's performance on test set\n",
        "\n",
        "correct_count, all_count = 0, 0\n",
        "for images,labels in test_iterator:\n",
        "      for image,label in zip(images,labels):\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            img = image.cuda()\n",
        "            lab = label.cuda()\n",
        "            img = img[None,].type('torch.cuda.FloatTensor')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_ = model(img) \n",
        "\n",
        "        pred_label = output_.argmax()\n",
        "\n",
        "        if(pred_label.item()==lab.item()):\n",
        "          correct_count += 1\n",
        "        all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Test Accuracy =\", (correct_count/(all_count)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MLz8C9_j8XKW",
        "outputId": "333c1f43-f75d-4fca-c0a1-6665c78e624f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn1.weight hidden layer dimension torch.Size([16, 1, 3, 3])\n",
            "Unique values of weight in cnn1.weight th hidden layer :  tensor([-1.,  0.,  1.], device='cuda:0')\n",
            "\n",
            "cnn1.bias hidden layer dimension torch.Size([16])\n",
            "Unique values of weight in cnn1.bias th hidden layer :  tensor([-1.,  0.,  1.], device='cuda:0')\n",
            "\n",
            "cnn2.weight hidden layer dimension torch.Size([32, 16, 3, 3])\n",
            "Unique values of weight in cnn2.weight th hidden layer :  tensor([-1.,  0.,  1.], device='cuda:0')\n",
            "\n",
            "cnn2.bias hidden layer dimension torch.Size([32])\n",
            "Unique values of weight in cnn2.bias th hidden layer :  tensor([-1.,  0.,  1.], device='cuda:0')\n",
            "\n",
            "fc1.weight hidden layer dimension torch.Size([10, 800])\n",
            "Unique values of weight in fc1.weight th hidden layer :  tensor([-1.,  0.,  1.], device='cuda:0')\n",
            "\n",
            "fc1.bias hidden layer dimension torch.Size([10])\n",
            "Unique values of weight in fc1.bias th hidden layer :  tensor([-1.,  0.,  1.], device='cuda:0')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# For each layer, model's ternary weights\n",
        "state_dict = model.state_dict()\n",
        "\n",
        "layer_distinct_weights = {}\n",
        "\n",
        "for i in layer_name:\n",
        "  imd = torch.unique(model.state_dict()[i])\n",
        "  print(i+ ' hidden layer dimension', model.state_dict()[i].shape)\n",
        "  print(\"Unique values of weight in \"+ i+ \" th hidden layer : \", imd)\n",
        "  layer_distinct_weights[i] = imd.cpu().numpy().tolist()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2b2AUdPD8XKX",
        "outputId": "e064e87b-0ac0-4eb0-b2bb-ef536b056273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cnn1.bias', 'cnn1.weight', 'cnn2.bias', 'cnn2.weight', 'fc1.bias', 'fc1.weight']\n"
          ]
        }
      ],
      "source": [
        "keys = list(state_dict.keys())\n",
        "print(keys)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in keys:\n",
        "  print(i, state_dict[i].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EA0erA-zpVz",
        "outputId": "73ec0cec-e4da-424e-a674-0d2493ac62b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn1.bias torch.Size([16])\n",
            "cnn1.weight torch.Size([16, 1, 3, 3])\n",
            "cnn2.bias torch.Size([32])\n",
            "cnn2.weight torch.Size([32, 16, 3, 3])\n",
            "fc1.bias torch.Size([10])\n",
            "fc1.weight torch.Size([10, 800])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Duplicate architecture of the CNN Model\n",
        "\n",
        "class CNNModel1(nn.Module):\n",
        "    def __init__(self, dn_info):\n",
        "        super(CNNModel1, self).__init__()\n",
        "\n",
        "        self.dn_info = dn_info       # Dead Neuron info\n",
        "        \n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=0, bias= True)\n",
        "     \n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0, bias= True)\n",
        "        \n",
        "        # Fully connected 1\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 10,bias= True) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Set 1\n",
        "        out = F.max_pool2d(F.relu(self.cnn1(x)),2)\n",
        "        \n",
        "        # Set 2\n",
        "        out = F.max_pool2d(F.relu(self.cnn2(out)),2) \n",
        "        \n",
        "        # Flatten\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        ####################################\n",
        "        # Storing dead neurons indices\n",
        "        idx1 = torch.where(out.cpu() == 0.)[1]\n",
        "        \n",
        "        for j in idx1:\n",
        "            self.dn_info[str(j.item())] += 1\n",
        "            \n",
        "        #####################################\n",
        "\n",
        "        # Dense\n",
        "        out = self.fc1(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "HxWZYM-auXe_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getDeadN_info(dn_info, unit, state_dict, ds, nameOftheSet):\n",
        "\n",
        "  for i in range(unit):\n",
        "      dn_info[str(i)] = 0\n",
        "      \n",
        "  model1 = CNNModel1(dn_info)\n",
        "  model1 = model1.cuda()\n",
        "\n",
        "  model1.load_state_dict(state_dict)\n",
        "\n",
        "  correct_count, all_count = 0, 0\n",
        "  model1.eval()\n",
        "\n",
        "  for images,labels in ds:\n",
        "        for image,label in zip(images,labels):\n",
        "\n",
        "          if torch.cuda.is_available():\n",
        "              img = image.cuda()\n",
        "              lab = label.cuda()\n",
        "              img = img[None,].type('torch.cuda.FloatTensor')\n",
        "\n",
        "          with torch.no_grad():\n",
        "              output_ = model1(img) \n",
        "\n",
        "          pred_label = output_.argmax()\n",
        "\n",
        "          if(pred_label.item()==lab.item()):\n",
        "            correct_count += 1\n",
        "          all_count += 1\n",
        "\n",
        "  print(\"Number Of Images =\", all_count)\n",
        "  print(f\"Model {nameOftheSet} Accuracy =\", (correct_count/(all_count)))"
      ],
      "metadata": {
        "id": "LZaOzYb3nnFj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RwBSskNQ8XKh",
        "outputId": "23d41102-0c5c-49dd-a1d0-2dcfa5d80a58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number Of Images = 50000\n",
            "Model Training Accuracy = 0.8528\n",
            "Number Of Images = 10000\n",
            "Model Validation Accuracy = 0.8465\n",
            "Number Of Images = 10000\n",
            "Model Test Accuracy = 0.893\n"
          ]
        }
      ],
      "source": [
        "dn_info_train = {}\n",
        "dn_info_val = {}\n",
        "dn_info_test = {}\n",
        "\n",
        "getDeadN_info(dn_info= dn_info_train, unit = 800, state_dict = state_dict, ds= train_iterator, nameOftheSet = \"Training\")\n",
        "getDeadN_info(dn_info= dn_info_val, unit = 800, state_dict = state_dict, ds= val_iterator, nameOftheSet = \"Validation\")\n",
        "getDeadN_info(dn_info= dn_info_test, unit = 800, state_dict = state_dict, ds= test_iterator, nameOftheSet = \"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bfjmgUpk8XKi",
        "outputId": "4bd7c95b-5dc2-4cfd-fa28-f1429045f0bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "max_dn_val = max(dn_info_val.values())\n",
        "max_dn_test = max(dn_info_test.values())\n",
        "max_dn_train = max(dn_info_train.values())\n",
        "max_dn_train, max_dn_val, max_dn_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JPwL725Y8XKj"
      },
      "outputs": [],
      "source": [
        "dead_n_idx = [] \n",
        "\n",
        "for i, j in dn_info_train.items():\n",
        "  if j == max_dn_train:\n",
        "    dead_n_idx.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qu3zF9uq8XKj",
        "outputId": "80a9337a-b324-4aeb-f749-8d7aeb194571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FC Layer : 75\n"
          ]
        }
      ],
      "source": [
        "print(\"FC Layer :\",len(dead_n_idx)) # Number of neurons that are dead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "blZi36Ca8XKq",
        "outputId": "6bb60301-2138-4470-dffa-5ea16b07e2a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '775', '776', '777', '778', '779', '780', '781', '782', '783', '784', '785', '786', '787', '788', '789', '790', '791', '792', '793', '794', '795', '796', '797', '798', '799']\n"
          ]
        }
      ],
      "source": [
        "print(dead_n_idx) # Indices of neuron that are dead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yb8LRo2Q8XKt"
      },
      "outputs": [],
      "source": [
        "state_dict1 = state_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_distinct_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se4SLLRRJhWT",
        "outputId": "c982773f-216d-4f0d-ccc9-3b2b19a84c0b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cnn1.bias': [-1.0, 0.0, 1.0],\n",
              " 'cnn1.weight': [-1.0, 0.0, 1.0],\n",
              " 'cnn2.bias': [-1.0, 0.0, 1.0],\n",
              " 'cnn2.weight': [-1.0, 0.0, 1.0],\n",
              " 'fc1.bias': [-1.0, 0.0, 1.0],\n",
              " 'fc1.weight': [-1.0, 0.0, 1.0]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "DNXNxCFs8XKx",
        "outputId": "16f15ff2-02ff-4880-cad2-edd15ae29f5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1.weight\n",
            "-1.0 0.0 1.0\n",
            "Total dead transitions for the output layer : 20\n"
          ]
        }
      ],
      "source": [
        "total_trans = 0\n",
        "layers_name = ['fc1.weight']\n",
        "\n",
        "for l in layers_name:\n",
        "  print(l)\n",
        "  z = state_dict1[l]\n",
        "\n",
        "  if len(layer_distinct_weights[l]) > 2 :\n",
        "    w_neg, w_0, w_pos =  layer_distinct_weights[l]\n",
        "    print(w_neg, w_0, w_pos)\n",
        "  else:\n",
        "    w_neg, w_pos = layer_distinct_weights[l]\n",
        "    print(w_neg,  w_pos)\n",
        "\n",
        "  for idx in dead_n_idx:\n",
        "      imd = z[:,eval(idx)]\n",
        "      trans = torch.where(imd == w_neg)[0].nelement() + torch.where(imd == w_pos)[0].nelement()\n",
        "      total_trans += trans * 2\n",
        "    \n",
        "print(\"Total dead transitions for the output layer :\", total_trans)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E64pYeIW8XK0"
      },
      "outputs": [],
      "source": [
        "# Fault coverage that we have obtained from main file : 2471 / 2740"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xAK4Mddws52K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c01eab2a-21f0-4216-e8b8-556c0a4b8739"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9091240875912409"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Adding more 60 transitions to the numerator will make the net fault coverage\n",
        "(2471 + 20)/2740"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RtzUQuw3QPpl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DeadNeurons.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}